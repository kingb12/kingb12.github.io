@inproceedings{king-flanigan-2024-unsupervised,
    title = "Unsupervised End-to-End Task-Oriented Dialogue with {LLM}s: The Power of the Noisy Channel",
    author = "King, Brendan  and
      Flanigan, Jeffrey",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.473",
    pages = "8283--8300",
    selected = {true},
    abstract = "Training task-oriented dialogue systems typically requires turn-level annotations for interacting with their APIs: e.g. a dialogue state and the system actions taken at each step. These annotations can be costly to produce, error-prone, and require both domain and annotation expertise. With advances in LLMs, we hypothesize that unlabeled data and a schema definition are sufficient for building a working task-oriented dialogue system, completely unsupervised. We consider a novel unsupervised setting of only (1) a well-defined API schema (2) a set of unlabeled dialogues between a user and agent. We propose an innovative approach using expectation-maximization (EM) that infers turn-level annotations as latent variables using a noisy channel model to build an end-to-end dialogue agent. Evaluating our approach on the MultiWOZ benchmark, our method more than doubles the dialogue success rate of a strong GPT-3.5 baseline.",
}
@inproceedings{king-flanigan-2023-diverse,
    title = "Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking",
    author = "King, Brendan  and
      Flanigan, Jeffrey",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.344",
    doi = "10.18653/v1/2023.findings-acl.344",
    pages = "5570--5585",
    selected = {true},
    abstract = "There has been significant interest in zero and few-shot learning for dialogue state tracking (DST) due to the high cost of collecting and annotating task-oriented dialogues. Recent work has demonstrated that in-context learning requires very little data and zero parameter updates, and even outperforms trained methods in the few-shot setting. We propose RefPyDST, which advances the state of the art with three advancements to in-context learning for DST.First, we formulate DST as a Python programming task, explicitly modeling language coreference as variable reference in Python. Second, since in-context learning depends highly on the context examples, we propose a method to retrieve a diverse set of relevant examples to improve performance. Finally, we introduce a novel re-weighting method during decoding that takes into account probabilities of competing surface forms, and produces a more accurate dialogue state prediction. We evaluate our approach using MultiWOZ and achieve state-of-the-art multi-domain joint-goal accuracy in zero and few-shot settings.",
}
@article{Richards2016MightyMM,
  title={Mighty morphing metabolic models: leveraging manual curations for automatic metabolic reconstruction of clades},
  author={Matthew A. Richards and Brendan King and Evangelos Simeonidis and Nathan D. Price},
  journal={F1000Research},
  year={2016},
  volume={5}
}
@inproceedings{cai_dda_2023,
  author    = {Jon Cai and Brendan King and Margaret Perkoff  and Shiran Dudy  and Jie Cao  and Marie Grace  and Natalia Wojarnik  and Ananya Ganesh  and James H. Martin  and Martha S. Palmer  and Marilyn A. Walker and Jeffrey Flanigan},
  title     = {Dependency Dialogue Acts â€” Annotation Scheme and Case Study},
  booktitle = {The 13th International Workshop on 
Spoken Dialogue Systems Technology, {IWSDS} 2023, Los Angeles, United States},
  year      = {2023},
  month = {february},
  selected = {true},
  pdf={https://arxiv.org/pdf/2302.12944.pdf}
}
@article{king_probannoweb_2018,
	title = {{ProbAnnoWeb} and {ProbAnnoPy}: probabilistic annotation and gap-filling of metabolic reconstructions},
	volume = {34},
	issn = {1367-4811},
	shorttitle = {{ProbAnnoWeb} and {ProbAnnoPy}},
	doi = {10.1093/bioinformatics/btx796},
	abstract = {SUMMARY: Gap-filling is a necessary step to produce quality genome-scale metabolic reconstructions capable of flux-balance simulation. Most available gap-filling tools use an organism-agnostic approach, where reactions are selected from a database to fill gaps without consideration of the target organism. Conversely, our likelihood based gap-filling with probabilistic annotations selects candidate reactions based on a likelihood score derived specifically from the target organism's genome. Here, we present two new implementations of probabilistic annotation and likelihood based gap-filling: a web service called ProbAnnoWeb, and a standalone python package called ProbAnnoPy.
AVAILABILITY AND IMPLEMENTATION: Our tools are available as a web service with no installation needed (ProbAnnoWeb) at probannoweb.systemsbiology.net, and as a local python package implementation (ProbAnnoPy) at github.com/PriceLab/probannopy.
CONTACT: evangelos.simeonidis@systemsbiology.org or nathan.price@systemsbiology.org.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {9},
	journal = {Bioinformatics (Oxford, England)},
	author = {King, Brendan and Farrah, Terry and Richards, Matthew A. and Mundy, Michael and Simeonidis, Evangelos and Price, Nathan D.},
	month = may,
	year = {2018},
	pmid = {29267848},
	keywords = {Genome, Likelihood Functions, Software},
	pages = {1594--1596},
	file = {King et al_2018_ProbAnnoWeb and ProbAnnoPy.pdf:/Users/bking/Zotero/storage/A25JTAXY/King et al_2018_ProbAnnoWeb and ProbAnnoPy.pdf:application/pdf},
  selected = {true}
}
